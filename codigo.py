import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import seaborn as sns

# --- Configuraci√≥n de la p√°gina de Streamlit ---
st.set_page_config(
    page_title="Simulaci√≥n de ML Supervisado Interactivo",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("Aplicaci√≥n Interactiva de Modelos de ML Supervisados üöÄ")
st.markdown("""
Esta aplicaci√≥n te permite **subir tu propio archivo CSV**, realizar un an√°lisis exploratorio,
entrenar varios modelos de clasificaci√≥n supervisada y comparar sus rendimientos.
""")

# --- Carga de Datos CSV ---
st.sidebar.header("Carga tu Conjunto de Datos")
uploaded_file = st.sidebar.file_uploader("Elige un archivo CSV", type="csv")

# Comprobamos si se ha subido un archivo
if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("¬°Archivo cargado exitosamente!")

        st.subheader("1. Vista Previa del Conjunto de Datos Cargado")
        st.write(f"Conjunto de datos cargado con **{df.shape[0]}** filas y **{df.shape[1]}** columnas.")
        st.dataframe(df.head())

        # --- Selecci√≥n de la Variable Objetivo (Clase) ---
        st.sidebar.markdown("---")
        st.sidebar.header("Configuraci√≥n del Conjunto de Datos")
        target_column = st.sidebar.selectbox(
            "Selecciona la columna que representa la variable objetivo (Clase):",
            df.columns
        )

        # Asignar X (caracter√≠sticas) y y (variable objetivo)
        # Se excluye la columna objetivo para X
        X = df.drop(columns=[target_column])
        y = df[target_column]

        # Validar si hay suficientes clases para clasificaci√≥n
        if y.nunique() < 2:
            st.error("La columna seleccionada no tiene al menos dos clases √∫nicas. Por favor, elige una columna diferente.")
            st.stop()

    except Exception as e:
        st.error(f"Error al leer el archivo. Aseg√∫rate de que sea un archivo CSV v√°lido. Error: {e}")
        st.stop() # Detiene la ejecuci√≥n si hay un error
else:
    st.info("Por favor, sube un archivo CSV para comenzar. Los modelos y gr√°ficos se mostrar√°n aqu√≠.")
    st.stop() # Detiene la ejecuci√≥n si no hay archivo subido

# --- Divisi√≥n de los datos en conjuntos de entrenamiento y prueba ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# --- An√°lisis Exploratorio de Datos (EDA) ---
st.markdown("---")
st.subheader("2. An√°lisis Exploratorio de Datos (EDA) üìä")

st.markdown("#### Estad√≠sticas Descriptivas")
st.dataframe(df.describe())

st.markdown("#### Matriz de Correlaci√≥n")
# Selecciona solo las columnas num√©ricas para el c√°lculo de la correlaci√≥n
numeric_df = X.select_dtypes(include=np.number)
if not numeric_df.empty and len(numeric_df.columns) > 1:
    fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
    sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=".2f", ax=ax_corr)
    plt.title("Matriz de Correlaci√≥n entre Caracter√≠sticas Num√©ricas")
    st.pyplot(fig_corr)
else:
    st.warning("No hay suficientes columnas num√©ricas para mostrar la matriz de correlaci√≥n.")

st.markdown("---")
st.markdown("#### Distribuci√≥n de Caracter√≠sticas")
# Obtiene solo las columnas num√©ricas para la selecci√≥n
numeric_cols = X.select_dtypes(include=np.number).columns.tolist()
selected_features_for_hist = st.multiselect(
    "Selecciona caracter√≠sticas para ver su distribuci√≥n:",
    options=numeric_cols,
    default=numeric_cols[0:min(3, len(numeric_cols))] if numeric_cols else []
)
if selected_features_for_hist:
    for feature in selected_features_for_hist:
        fig_hist, ax_hist = plt.subplots(figsize=(8, 5))
        sns.histplot(X[feature], kde=True, ax=ax_hist, color='skyblue')
        plt.title(f"Distribuci√≥n de {feature}")
        plt.xlabel(feature)
        plt.ylabel("Frecuencia")
        st.pyplot(fig_hist)
else:
    st.info("No hay caracter√≠sticas num√©ricas para graficar histogramas.")


st.markdown("#### Gr√°fico de Dispersi√≥n Interactivo (Primeras dos caracter√≠sticas)")
st.write("Visualizaci√≥n de las dos primeras caracter√≠sticas num√©ricas principales por clase.")
numeric_cols = X.select_dtypes(include=np.number).columns.tolist()
if len(numeric_cols) >= 2:
    fig_scatter, ax_scatter = plt.subplots(figsize=(10, 8))
    sns.scatterplot(
        x=df[numeric_cols[0]],
        y=df[numeric_cols[1]],
        hue=df[target_column],
        palette='viridis',
        marker='o',
        s=100,
        edgecolor='k',
        ax=ax_scatter
    )
    plt.title(f"Dispersi√≥n de '{numeric_cols[0]}' vs '{numeric_cols[1]}' por Clase")
    plt.xlabel(numeric_cols[0])
    plt.ylabel(numeric_cols[1])
    st.pyplot(fig_scatter)
else:
    st.warning("No hay suficientes caracter√≠sticas num√©ricas para el gr√°fico de dispersi√≥n.")


# --- Selecci√≥n de Modelo y Par√°metros ---
st.markdown("---")
st.subheader("3. Selecci√≥n y Entrenamiento de Modelos ü§ñ")

st.sidebar.header("Configuraci√≥n de Modelos ML")
model_choices = st.sidebar.multiselect(
    "Selecciona 1 a 5 Modelos de Clasificaci√≥n:",
    ["K-Nearest Neighbors (KNN)", "√Årbol de Decisi√≥n", "Clasificador Bayesiano Gausiano", "Support Vector Machine (SVM)", "Regresi√≥n Log√≠stica"],
    default=["K-Nearest Neighbors (KNN)", "√Årbol de Decisi√≥n"]
)

models = {}
metrics_results = []

for model_name in model_choices:
    st.markdown(f"#### Par√°metros para: {model_name}")
    model = None

    if model_name == "K-Nearest Neighbors (KNN)":
        n_neighbors = st.sidebar.slider(f"KNN: N√∫mero de Vecinos (k) para {model_name}", min_value=1, max_value=20, value=5, key=f"{model_name}_k")
        model = KNeighborsClassifier(n_neighbors=n_neighbors)
    elif model_name == "√Årbol de Decisi√≥n":
        max_depth = st.sidebar.slider(f"√Årbol: Profundidad M√°xima para {model_name}", min_value=3, max_value=15, value=7, key=f"{model_name}_depth")
        min_samples_leaf = st.sidebar.slider(f"√Årbol: M√≠nimo de Muestras por Hoja para {model_name}", min_value=1, max_value=10, value=3, key=f"{model_name}_leaf")
        model = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42)
    elif model_name == "Clasificador Bayesiano Gausiano":
        model = GaussianNB()
    elif model_name == "Support Vector Machine (SVM)":
        C_svm = st.sidebar.slider(f"SVM: Par√°metro de Regularizaci√≥n (C) para {model_name}", min_value=0.1, max_value=10.0, value=1.0, step=0.1, key=f"{model_name}_C")
        kernel_svm = st.sidebar.selectbox(f"SVM: Kernel para {model_name}", ("rbf", "linear", "poly", "sigmoid"), key=f"{model_name}_kernel")
        model = SVC(C=C_svm, kernel=kernel_svm, random_state=42)
    elif model_name == "Regresi√≥n Log√≠stica":
        C_lr = st.sidebar.slider(f"Regresi√≥n Log√≠stica: Par√°metro de Regularizaci√≥n (C) para {model_name}", min_value=0.1, max_value=10.0, value=1.0, step=0.1, key=f"{model_name}_C")
        solver_lr = st.sidebar.selectbox(f"Regresi√≥n Log√≠stica: Solver para {model_name}", ("liblinear", "lbfgs", "sag", "saga"), key=f"{model_name}_solver")
        model = LogisticRegression(C=C_lr, solver=solver_lr, max_iter=1000, random_state=42)

    if model:
        st.write(f"Entrenando {model_name}...")
        try:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred, output_dict=True)

            st.write(f"### Resultados para {model_name}")
            st.metric(label="Exactitud (Accuracy)", value=f"{accuracy:.4f}")

            with st.expander(f"Ver Reporte de Clasificaci√≥n para {model_name}"):
                report_df = pd.DataFrame(report).transpose()
                st.dataframe(report_df)

            with st.expander(f"Ver Matriz de Confusi√≥n para {model_name}"):
                fig_cm, ax_cm = plt.subplots(figsize=(6, 5))
                cm_display = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap=plt.cm.Blues, ax=ax_cm)
                st.pyplot(fig_cm)

            if model_name == "√Årbol de Decisi√≥n":
                with st.expander("Ver Visualizaci√≥n del √Årbol de Decisi√≥n"):
                    fig_tree, ax_tree = plt.subplots(figsize=(20, 15))
                    plot_tree(model, filled=True, feature_names=X.columns.tolist(), class_names=[str(c) for c in sorted(y.unique())], ax=ax_tree, fontsize=8)
                    st.pyplot(fig_tree)

            metrics_results.append({
                "Modelo": model_name,
                "Exactitud": accuracy,
                "Precisi√≥n (Macro Avg)": report['macro avg']['precision'],
                "Recall (Macro Avg)": report['macro avg']['recall'],
                "F1-Score (Macro Avg)": report['macro avg']['f1-score']
            })
        except Exception as e:
            st.error(f"Error al entrenar {model_name}: {e}")

# --- Comparaci√≥n de Modelos ---
st.markdown("---")
st.subheader("4. Comparaci√≥n de Modelos ‚ú®")

if metrics_results:
    comparison_df = pd.DataFrame(metrics_results).set_index("Modelo")
    st.dataframe(comparison_df.style.highlight_max(axis=0, color='lightgreen'))

    st.markdown("#### Gr√°fico de Comparaci√≥n de Exactitud")
    fig_comp, ax_comp = plt.subplots(figsize=(10, 6))
    sns.barplot(x=comparison_df.index, y="Exactitud", data=comparison_df, palette="viridis", ax=ax_comp)
    plt.ylim(0, 1)
    plt.title("Comparaci√≥n de Exactitud de los Modelos")
    plt.ylabel("Exactitud")
    plt.xlabel("Modelo")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    st.pyplot(fig_comp)
else:
    st.warning("Selecciona al menos un modelo para ver la comparaci√≥n.")

st.markdown("---")
st.markdown("¬°Gracias por usar esta aplicaci√≥n interactiva!")
